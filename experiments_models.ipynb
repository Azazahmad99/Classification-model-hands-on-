{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad590291-d97a-4859-ad64-f92c413117cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab564be-220c-48fb-aee2-bc73e45abd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_df = pd.read_csv(r\"DSW_ML_Test/historic.csv\")\n",
    "prediction_df = pd.read_csv(r\"DSW_ML_Test/prediction_input.csv\")\n",
    "\n",
    "# Check for missing values in both datasets\n",
    "historic_missing = historic_df.isnull().sum()\n",
    "prediction_missing = prediction_df.isnull().sum()\n",
    "\n",
    "# Summary statistics for the numerical column 'stars'\n",
    "historic_stats = historic_df['stars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdacf491-39ea-4957-b3e7-17fb047a9f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400, 18), (1600, 18), (6400,), (1600,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing steps for the historic data with One-Hot Encoding and Label Encoding\n",
    "# Preprocessing steps for the historic data with One-Hot Encoding and Label Encoding\n",
    "def preprocess_historic_data(df):\n",
    "    # Encode the 'success_indicator' label (top = 1, flop = 0) using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['success_indicator'] = label_encoder.fit_transform(df['success_indicator'])\n",
    "    \n",
    "    # One-Hot Encode the categorical columns ('category', 'main_promotion', 'color')\n",
    "    df = pd.get_dummies(df, columns=['category', 'main_promotion', 'color'], prefix=['category', 'promotion', 'color'], drop_first=True)\n",
    "    \n",
    "    return df, label_encoder\n",
    "\n",
    "# Apply preprocessing to historic data\n",
    "historic_df_processed, label_encoder = preprocess_historic_data(historic_df)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = historic_df_processed.drop(columns=['item_no', 'success_indicator'])\n",
    "y = historic_df_processed['success_indicator']\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display the shape of the training and test sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560c3758-7560-4a07-9685-e0ed45ffce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "logreg_report = classification_report(y_test, y_pred_logreg, target_names=['flop', 'top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e5a29fe-6fec-4739-9534-0cdcf73b1f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.825625,\n",
       " '              precision    recall  f1-score   support\\n\\n        flop       0.80      0.67      0.73       563\\n         top       0.84      0.91      0.87      1037\\n\\n    accuracy                           0.83      1600\\n   macro avg       0.82      0.79      0.80      1600\\nweighted avg       0.82      0.83      0.82      1600\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_accuracy , logreg_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc7664e0-2557-43b8-9ce8-d83cddc46443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n        flop       0.80      0.67      0.73       563\\n         top       0.84      0.91      0.87      1037\\n\\n    accuracy                           0.83      1600\\n   macro avg       0.82      0.79      0.80      1600\\nweighted avg       0.82      0.83      0.82      1600\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fb19c4-93cd-46fe-92da-32904eac6c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>category_Hoodie</th>\n",
       "      <th>category_Polo-Shirt</th>\n",
       "      <th>category_Sweatshirt</th>\n",
       "      <th>category_T-Shirt</th>\n",
       "      <th>category_Tunic</th>\n",
       "      <th>promotion_Category_Highlight</th>\n",
       "      <th>promotion_Display_Ad_Campaign</th>\n",
       "      <th>promotion_Frontpage_Header</th>\n",
       "      <th>color_Blue</th>\n",
       "      <th>color_Brown</th>\n",
       "      <th>color_Green</th>\n",
       "      <th>color_Multi-Color</th>\n",
       "      <th>color_Orange</th>\n",
       "      <th>color_Pink</th>\n",
       "      <th>color_Red</th>\n",
       "      <th>color_White</th>\n",
       "      <th>color_Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>1.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>4.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>4.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>3.3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>3.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>4.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>4.3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>4.7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>2.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars  category_Hoodie  category_Polo-Shirt  category_Sweatshirt  \\\n",
       "7485    1.9            False                False                False   \n",
       "7826    4.5            False                False                False   \n",
       "4681    4.6            False                False                False   \n",
       "4203    2.5            False                False                False   \n",
       "5097    3.3             True                False                False   \n",
       "...     ...              ...                  ...                  ...   \n",
       "1237    3.6            False                False                False   \n",
       "601     4.8            False                False                False   \n",
       "858     4.3            False                 True                False   \n",
       "6883    4.7            False                False                False   \n",
       "7329    2.5            False                 True                False   \n",
       "\n",
       "      category_T-Shirt  category_Tunic  promotion_Category_Highlight  \\\n",
       "7485              True           False                         False   \n",
       "7826              True           False                         False   \n",
       "4681             False            True                         False   \n",
       "4203             False            True                          True   \n",
       "5097             False           False                          True   \n",
       "...                ...             ...                           ...   \n",
       "1237             False            True                         False   \n",
       "601              False           False                         False   \n",
       "858              False           False                         False   \n",
       "6883             False           False                         False   \n",
       "7329             False           False                         False   \n",
       "\n",
       "      promotion_Display_Ad_Campaign  promotion_Frontpage_Header  color_Blue  \\\n",
       "7485                          False                       False       False   \n",
       "7826                           True                       False       False   \n",
       "4681                           True                       False       False   \n",
       "4203                          False                       False       False   \n",
       "5097                          False                       False       False   \n",
       "...                             ...                         ...         ...   \n",
       "1237                          False                       False       False   \n",
       "601                            True                       False       False   \n",
       "858                           False                        True        True   \n",
       "6883                          False                        True       False   \n",
       "7329                          False                       False       False   \n",
       "\n",
       "      color_Brown  color_Green  color_Multi-Color  color_Orange  color_Pink  \\\n",
       "7485        False        False               True         False       False   \n",
       "7826        False        False              False         False       False   \n",
       "4681        False        False               True         False       False   \n",
       "4203        False        False              False         False       False   \n",
       "5097        False        False               True         False       False   \n",
       "...           ...          ...                ...           ...         ...   \n",
       "1237        False        False              False         False       False   \n",
       "601          True        False              False         False       False   \n",
       "858         False        False              False         False       False   \n",
       "6883        False        False              False         False       False   \n",
       "7329        False        False              False          True       False   \n",
       "\n",
       "      color_Red  color_White  color_Yellow  \n",
       "7485      False        False         False  \n",
       "7826       True        False         False  \n",
       "4681      False        False         False  \n",
       "4203      False        False          True  \n",
       "5097      False        False         False  \n",
       "...         ...          ...           ...  \n",
       "1237       True        False         False  \n",
       "601       False        False         False  \n",
       "858       False        False         False  \n",
       "6883      False        False         False  \n",
       "7329      False        False         False  \n",
       "\n",
       "[6400 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "636d998f-7523-4987-ad38-9e0cae093916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.825625\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        flop       0.80      0.67      0.73       563\n",
      "         top       0.84      0.91      0.87      1037\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.82      0.79      0.80      1600\n",
      "weighted avg       0.82      0.83      0.82      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "logreg_report = classification_report(y_test, y_pred_logreg, target_names=['flop', 'top'])\n",
    "\n",
    "# Print results\n",
    "print(f'Logistic Regression Accuracy: {logreg_accuracy}')\n",
    "print(f'Classification Report:\\n{logreg_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51f5a28d-2a8e-4f4e-8336-33b13b8b0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Scores: [0.80546875 0.8171875  0.83515625 0.81484375 0.81484375]\n",
      "Mean CV Accuracy: 0.8175000000000001\n",
      "Standard Deviation of CV Accuracy: 0.009702609185162544\n"
     ]
    }
   ],
   "source": [
    "# Apply K-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-Fold Cross Validation\n",
    "\n",
    "# Use cross_val_score to evaluate the model's accuracy across different folds\n",
    "logreg_cv_scores = cross_val_score(logreg_model, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print Cross Validation results\n",
    "print(f\"Logistic Regression Cross-Validation Scores: {logreg_cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {logreg_cv_scores.mean()}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {logreg_cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c3a69a5-582e-41d6-aacf-699fe4d1d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8375\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        flop       0.79      0.73      0.76       563\n",
      "         top       0.86      0.90      0.88      1037\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.83      0.81      0.82      1600\n",
      "weighted avg       0.84      0.84      0.84      1600\n",
      "\n",
      "XGBoost Cross-Validation Scores: [0.83671875 0.84296875 0.85078125 0.84453125 0.83359375]\n",
      "Mean CV Accuracy: 0.8417187500000001\n",
      "Standard Deviation of CV Accuracy: 0.0060434623768167986\n"
     ]
    }
   ],
   "source": [
    "# Create an XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Train the XGBoost model on the training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model performance on the test set\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "xgb_report = classification_report(y_test, y_pred_xgb, target_names=['flop', 'top'])\n",
    "\n",
    "# Print results from the test set\n",
    "print(f'XGBoost Accuracy: {xgb_accuracy}')\n",
    "print(f'Classification Report:\\n{xgb_report}')\n",
    "\n",
    "# Apply K-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-Fold Cross Validation\n",
    "\n",
    "# Use cross_val_score to evaluate the model's accuracy across different folds\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print Cross Validation results\n",
    "print(f\"XGBoost Cross-Validation Scores: {xgb_cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {xgb_cv_scores.mean()}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {xgb_cv_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b797bbe0-2c2a-4029-9409-5668f77ecf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6127 - loss: 0.6241 - val_accuracy: 0.7977 - val_loss: 0.4746\n",
      "Epoch 2/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.4569 - val_accuracy: 0.8281 - val_loss: 0.4484\n",
      "Epoch 3/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4323 - val_accuracy: 0.8391 - val_loss: 0.4345\n",
      "Epoch 4/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.4265 - val_accuracy: 0.8391 - val_loss: 0.4325\n",
      "Epoch 5/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.4152 - val_accuracy: 0.8438 - val_loss: 0.4276\n",
      "Epoch 6/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.4124 - val_accuracy: 0.8469 - val_loss: 0.4267\n",
      "Epoch 7/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.4103 - val_accuracy: 0.8477 - val_loss: 0.4260\n",
      "Epoch 8/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.4112 - val_accuracy: 0.8469 - val_loss: 0.4239\n",
      "Epoch 9/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.4020 - val_accuracy: 0.8383 - val_loss: 0.4302\n",
      "Epoch 10/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 0.3984 - val_accuracy: 0.8469 - val_loss: 0.4187\n",
      "Epoch 11/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 0.4063 - val_accuracy: 0.8445 - val_loss: 0.4206\n",
      "Epoch 12/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8535 - loss: 0.4059 - val_accuracy: 0.8539 - val_loss: 0.4150\n",
      "Epoch 13/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8625 - loss: 0.3887 - val_accuracy: 0.8500 - val_loss: 0.4212\n",
      "Epoch 14/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.3975 - val_accuracy: 0.8531 - val_loss: 0.4189\n",
      "Epoch 15/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3921 - val_accuracy: 0.8578 - val_loss: 0.4090\n",
      "Epoch 16/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8624 - loss: 0.3841 - val_accuracy: 0.8523 - val_loss: 0.4132\n",
      "Epoch 17/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8564 - loss: 0.4032 - val_accuracy: 0.8492 - val_loss: 0.4164\n",
      "Epoch 18/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8558 - loss: 0.3901 - val_accuracy: 0.8422 - val_loss: 0.4221\n",
      "Epoch 19/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3936 - val_accuracy: 0.8570 - val_loss: 0.4086\n",
      "Epoch 20/20\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.3776 - val_accuracy: 0.8477 - val_loss: 0.4158\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.4156\n",
      "ANN Test Accuracy: 0.8387500047683716\n",
      "K-Fold Cross-Validation Scores: [0.83984375, 0.8515625, 0.8804687261581421, 0.842968761920929, 0.83984375]\n",
      "Mean CV Accuracy: 0.8509374976158142\n",
      "Standard Deviation of CV Accuracy: 0.015376132856483414\n",
      "Best: 0.8543767748387349 using {'batch_size': 16, 'optimizer': 'sgd'}\n",
      "0.8539078051236039 with: {'batch_size': 16, 'optimizer': 'adam'}\n",
      "0.8543767748387349 with: {'batch_size': 16, 'optimizer': 'sgd'}\n",
      "0.8535952562878485 with: {'batch_size': 32, 'optimizer': 'adam'}\n",
      "0.8495324143460209 with: {'batch_size': 32, 'optimizer': 'sgd'}\n",
      "0.8525019212086941 with: {'batch_size': 64, 'optimizer': 'adam'}\n",
      "0.8525019944394429 with: {'batch_size': 64, 'optimizer': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple ANN model\n",
    "def create_ann_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the ANN model\n",
    "ann_model = create_ann_model(X_train.shape[1])\n",
    "\n",
    "# Train the model\n",
    "ann_history = ann_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "ann_loss, ann_accuracy = ann_model.evaluate(X_test, y_test)\n",
    "print(f'ANN Test Accuracy: {ann_accuracy}')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    # Ensure you use .iloc for DataFrame indexing\n",
    "    X_train_kf, X_val_kf = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_kf, y_val_kf = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    model_kf = create_ann_model(X_train.shape[1])\n",
    "    model_kf.fit(X_train_kf, y_train_kf, epochs=20, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = model_kf.evaluate(X_val_kf, y_val_kf, verbose=0)\n",
    "    cv_scores.append(val_accuracy)\n",
    "\n",
    "print(f\"K-Fold Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {np.mean(cv_scores)}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {np.std(cv_scores)}\")\n",
    "\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV (using a wrapper for Keras)\n",
    "\n",
    "\n",
    "def create_model(optimizer='adam'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd'],  \n",
    "    'batch_size': [16, 32, 64],    \n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize the results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} with: {param}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-conda-env-kernel",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
